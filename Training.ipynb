{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from models import SciNet\n",
    "from utils import target_loss \n",
    "from loader import build_dataloader\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 105)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup scinet model with 3 latent neurons\n",
    "scinet = SciNet(51,1,7,64)\n",
    "\n",
    "# Load and prepare training data\n",
    "dataloader = build_dataloader(batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (32x49 and 51x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32ms:\\[ Papers ]\\[paper]\\[DL for pratical motion detection]\\implement\\physics_discovery_\\Training.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/%5B%20Papers%20%5D/%5Bpaper%5D/%5BDL%20for%20pratical%20motion%20detection%5D/implement/physics_discovery_/Training.ipynb#W4sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/%5B%20Papers%20%5D/%5Bpaper%5D/%5BDL%20for%20pratical%20motion%20detection%5D/implement/physics_discovery_/Training.ipynb#W4sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m# print(inputs[0])\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/s%3A/%5B%20Papers%20%5D/%5Bpaper%5D/%5BDL%20for%20pratical%20motion%20detection%5D/implement/physics_discovery_/Training.ipynb#W4sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m pred \u001b[39m=\u001b[39m scinet\u001b[39m.\u001b[39;49mforward(inputs)\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/%5B%20Papers%20%5D/%5Bpaper%5D/%5BDL%20for%20pratical%20motion%20detection%5D/implement/physics_discovery_/Training.ipynb#W4sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m# print(pred)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/%5B%20Papers%20%5D/%5Bpaper%5D/%5BDL%20for%20pratical%20motion%20detection%5D/implement/physics_discovery_/Training.ipynb#W4sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m# break\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/s%3A/%5B%20Papers%20%5D/%5Bpaper%5D/%5BDL%20for%20pratical%20motion%20detection%5D/implement/physics_discovery_/Training.ipynb#W4sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m loss \u001b[39m=\u001b[39m target_loss(pred, outputs) \u001b[39m+\u001b[39m beta \u001b[39m*\u001b[39m scinet\u001b[39m.\u001b[39mkl_loss\n",
      "File \u001b[1;32ms:\\[ Papers ]\\[paper]\\[DL for pratical motion detection]\\implement\\physics_discovery_\\models.py:52\u001b[0m, in \u001b[0;36mSciNet.forward\u001b[1;34m(self, obs)\u001b[0m\n\u001b[0;32m     50\u001b[0m obs \u001b[39m=\u001b[39m obs[:,\u001b[39m0\u001b[39m:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     51\u001b[0m \u001b[39m# print('obs: ', obs)\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent_r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoder(obs) \n\u001b[0;32m     53\u001b[0m \u001b[39m# print('latent_r: ', self.latent_r)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m dec_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat( (q, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent_r), \u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32ms:\\[ Papers ]\\[paper]\\[DL for pratical motion detection]\\implement\\physics_discovery_\\models.py:26\u001b[0m, in \u001b[0;36mSciNet.encoder\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mencoder\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m---> 26\u001b[0m \tz \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49menc1(x))\n\u001b[0;32m     27\u001b[0m \tz \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39menc2(z))\n\u001b[0;32m     28\u001b[0m \tz \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatent(z)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (32x49 and 51x64)"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "SAVE_PATH = \"trained_models/scinet1.dat\"\n",
    "N_EPOCHS = 150\n",
    "optimizer = optim.Adam(scinet.parameters())\n",
    "hist_error = []\n",
    "hist_loss = []\n",
    "beta = 0.5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(N_EPOCHS):  \n",
    "    epoch_error = []\n",
    "    epoch_loss = []\n",
    "    for i_batch, minibatch in enumerate(dataloader):\n",
    "        time_series, _, _, question, answer = minibatch['time_series'], minibatch['fr'], minibatch['st'], minibatch['question'], minibatch['answer']\n",
    "        \n",
    "        # concat the time series with the features\n",
    "        inputs = torch.cat((time_series, question.reshape(-1, 1)), 1)\n",
    "        # build the output\n",
    "        outputs = answer\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # print(inputs[0])\n",
    "        pred = scinet.forward(inputs)\n",
    "        # print(pred)\n",
    "        # break\n",
    "        loss = target_loss(pred, outputs) + beta * scinet.kl_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        error = torch.mean(torch.sqrt((pred[:,0]-outputs)**2)).detach().numpy()\n",
    "        epoch_error.append(error)\n",
    "        epoch_loss.append(loss.data.detach().numpy())\n",
    "    # break\n",
    "    hist_error.append(np.mean(epoch_error))\n",
    "    hist_loss.append(np.mean(epoch_loss))\n",
    "    print(\"Epoch %d -- loss %f, RMS error %f \" % (epoch+1, hist_loss[-1], hist_error[-1]))\n",
    "torch.save(scinet.state_dict(), SAVE_PATH)\n",
    "print(\"Model saved to %s\" % SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot some training history data\n",
    "%matplotlib inline \n",
    "f, (ax1, ax2) = plt.subplots(2, 1, sharex=True)\n",
    "ax1.plot(hist_error)\n",
    "ax1.set_ylabel(\"Amplitude RMSE\")\n",
    "ax2.plot(hist_loss)\n",
    "ax2.set_ylabel(\"Loss\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
