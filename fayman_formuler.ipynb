{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7562871068304bd1b852611896cab180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a76101ea15345f5b18a2f7075a97bc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2fc3cab6ab470a95e43047eb22d46d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from datasets import load_dataset\n",
    "from tools import *\n",
    "from model import *\n",
    "from train import *\n",
    "from plot import *\n",
    "from eval import *\n",
    "\n",
    "# https://huggingface.co/datasets/yoshitomo-matsubara/srsd-feynman_easy\n",
    "dataset = load_dataset('yoshitomo-matsubara/srsd-feynman_easy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(n_equation, plot=False, save=True, dist=True):\n",
    "    train_loader, test_loader, features_, labels_, features, labels = prepare_data_loaders(dataset, n_equation, batch_size=batch_size, equation_size=equation_size)\n",
    "    hist_train_loss, hist_test_loss = train_model(formuler, train_loader, test_loader, optimizer, criterion, scheduler, num_epochs)\n",
    "    if plot:\n",
    "        plot_loss_curves(hist_train_loss, hist_test_loss, start=0)\n",
    "        # Plotting for training data\n",
    "        x_train, formula_train = formuler(features_.to(device))\n",
    "        x_train = x_train.detach().cpu()\n",
    "        print(criterion(x_train.squeeze(1), labels_))\n",
    "        print(features_.shape)\n",
    "        plot_grid(features_, x_train, labels_, \"Train\")\n",
    "\n",
    "        # Plotting for testing data\n",
    "        x_test, formula_test = formuler(features.to(device))\n",
    "        x_test = x_test.detach().cpu()\n",
    "        print(criterion(x_test.squeeze(1), labels))\n",
    "        print(features.shape)\n",
    "        plot_grid(features, x_test, labels, \"Test\")\n",
    "        if dist:\n",
    "            plot_gradient_distributions(formuler, features_, device)\n",
    "\n",
    "    min_loss, min_for = generate_minimal_loss_formula(formuler, features, features_, labels, device, criterion, model, prob_size=prob_size)\n",
    "    if plot:\n",
    "        x = decode(min_for, features.to(device))\n",
    "        print(criterion(x.squeeze(1).requires_grad_(), labels.to(device)).detach().cpu())\n",
    "        x = x.detach().cpu()\n",
    "        plot_grid(features, x, labels, \"predicted formula\")\n",
    "    if save:\n",
    "        torch.save(model, f'saved_models\\model-formula-{n_equation}.pth')\n",
    "    return min_loss, min_for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "EPOCH[0] test loss: 1303.454411, train loss: 3622.854980, weighted_loss: 3622.854980\n",
      "EPOCH[1] test loss: 1296.263567, train loss: 599.661682, weighted_loss: 599.661682\n",
      "EPOCH[2] test loss: 1295.865403, train loss: 604.370300, weighted_loss: 604.370300\n",
      "EPOCH[3] test loss: 1436.325776, train loss: 599.922180, weighted_loss: 599.922180\n",
      "EPOCH[4] test loss: 23112.074238, train loss: 133385000.000000, weighted_loss: 133385000.000000\n"
     ]
    }
   ],
   "source": [
    "equation_size = 30\n",
    "batch_size = 60\n",
    "num_epochs = 25\n",
    "prob_size = 4\n",
    "losses = []\n",
    "formulas = []\n",
    "equations = [7]\n",
    "for n_equation in equations:\n",
    "    print(n_equation)\n",
    "    x, y = data_prep(dataset, \"test\", n_equation, 30)\n",
    "    input_size = x.shape[1]\n",
    "    model = [input_size, input_size, input_size, input_size , 3, 2, 1]\n",
    "    formuler = Formuler(model).to(device)\n",
    "    optimizer = optim.Adam(formuler.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs, eta_min=0.0001)\n",
    "    criterion =  torch.nn.MSELoss()\n",
    "    min_loss, min_for = run_experiment(n_equation, plot=True, save=False, dist=False)\n",
    "    losses.append(min_loss)\n",
    "    formulas.append(min_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1317.4136962890625],\n",
       " [[[['g', 0], ['ln', 0], ['cos', 2], ['g', 1]],\n",
       "   [[0, '/', 2], [0, '/', 1], [2, '+', 3]],\n",
       "   [['cos', 1], ['cos', 2]],\n",
       "   [[0, '/', 1]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses, formulas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "n2a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
